# agent_module.py
import threading
import queue
import json
import torch
import time

from dotenv import load_dotenv
load_dotenv()

from langchain.chat_models import init_chat_model
from typing import Annotated
from typing_extensions import TypedDict

from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages

from langchain_google_community import GoogleSearchAPIWrapper
from langchain.tools import tool
from langgraph.types import Command, interrupt
from langchain_core.tools import InjectedToolCallId
from langchain_core.messages import ToolMessage
from langgraph.prebuilt import ToolNode, tools_condition
from langgraph.checkpoint.memory import MemorySaver

from langchain_core.runnables import RunnableConfig

from isaaclab.managers import SceneEntityCfg

from tools import *
import env_state


# --- 1) State íƒ€ì… ì •ì˜ (messages í•„ë“œë§Œ ìˆìœ¼ë©´ ì¶©ë¶„) ---
class State(TypedDict):
    messages: Annotated[list, add_messages]

# --- 2) íˆ´ ì •ì˜ ---
@tool
def time_travel(tool_call_id: Annotated[str, InjectedToolCallId], step_index: int=None):
    """ 
    LangGraphì˜ ìƒíƒœ(state) íˆìŠ¤í† ë¦¬ì—ì„œ ì›í•˜ëŠ” ì‹œì (step_index)ìœ¼ë¡œ ëŒì•„ê°‘ë‹ˆë‹¤.
    step_indexê°€ Noneì´ë©´ ì „ì²´ íˆìŠ¤í† ë¦¬ë¥¼ ì¶œë ¥í•˜ê³ ,
    ê°’ì´ ì£¼ì–´ì§€ë©´ í•´ë‹¹ ì‹œì ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.
    """
    history = list(graph.get_state_history(config))
    if not history:
        return "No state history available."
    if step_index is None:
        for state in history:
            print("Num Messages: ", len(state.values["messages"]), "Next: ", state.next)
            print("-" * 80)
        return f"Available steps: 0 ~ {len(history) - 1}. Use time_travel(step_index) to replay."
    if step_index < 0 or step_index >= len(history):
        return f"Invalid step_index: {step_index}. Available steps: 0 ~ {len(history) - 1}."
    to_replay = history[step_index]
    # ë°˜ë“œì‹œ í•´ë‹¹ ì‹œì ì˜ messagesë¥¼ ë„£ê³ , ToolMessageë„ ì¶”ê°€.
    replay_message = f"Replayed to step {step_index}."
    new_messages = to_replay.values["messages"] + [ToolMessage(replay_message, tool_call_id=tool_call_id)]
    return Command(update={"messages": new_messages})



@tool
def asynchronous_timer(
    timer: float,
    tool_call_id: Annotated[str, InjectedToolCallId]
) -> Command:
    """
    ğŸŸ¢ **ì¤‘ë‹¨ ì—†ì´ ì‹¤í–‰ë˜ëŠ” ë™ì‘ì„ ìœ„í•œ ë¹„ì°¨ë‹¨í˜• íƒ€ì´ë¨¸**ì…ë‹ˆë‹¤.

    ì´ íƒ€ì´ë¨¸ëŠ” ë¡œë´‡ì´ ë¹„êµì  ê¸´ ì‹œê°„ ë™ì•ˆ ì›€ì§ì—¬ì•¼ í•  ë•Œ ì‚¬ìš©ë˜ë©°,  
    `blocking_timer`ì™€ ë‹¬ë¦¬ LLMì˜ íŒë‹¨ íë¦„ì„ ë©ˆì¶”ì§€ ì•Šê³  ìœ ì§€í•  ìˆ˜ ìˆì–´  
    ë” ìœ ì—°í•˜ê³  ë¶€ë“œëŸ¬ìš´ í–‰ë™ ê³„íšì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

    ì£¼ìš” ì‚¬ìš© ì‚¬ë¡€:
    - 0.5ì´ˆ ì´ìƒ ì „ì§„ ë˜ëŠ” íšŒì „
    - ë„“ì€ ê³µê°„ì—ì„œì˜ íƒìƒ‰ ë˜ëŠ” ì£¼í–‰
    - ì¤‘ë‹¨ ì—†ì´ ì§„í–‰ë˜ëŠ” ì—°ì† ë™ì‘ ì œì–´

    ë™ì‘ ë°©ì‹:
    - ì§€ì •í•œ ì‹œê°„ì´ ì§€ë‚˜ë©´ `asynchronous_timer_expired()` í•¨ìˆ˜ê°€ ìë™ìœ¼ë¡œ í˜¸ì¶œë˜ì–´  
      LLMì´ ë‹¤ìŒ í–‰ë™ì„ ìƒì„±í•  ìˆ˜ ìˆë„ë¡ íë¦„ì„ ì´ì–´ì¤ë‹ˆë‹¤.

    ì°¸ê³  ì‚¬í•­:
    - **ì˜ˆì¸¡ ê°€ëŠ¥í•œ ê²½ë¡œì—ì„œ LLM í˜¸ì¶œ íšŸìˆ˜ë¥¼ ì¤„ì´ê³ ì í•  ë•Œ** ì´ìƒì ì…ë‹ˆë‹¤.
    - íŠ¹ë³„íˆ ì •ë°€í•œ ì œì–´ê°€ í•„ìš”í•œ ê²½ìš°ê°€ ì•„ë‹ˆë¼ë©´, ê¸°ë³¸ì ìœ¼ë¡œ ì´ íƒ€ì´ë¨¸ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.
    """
    env = env_state.get_env()
    dt = env.sim.get_physics_dt()
    steps = int(timer / dt)

    def _wait_and_expire(step_count: int, call_id: str):
        start = env_state.get_timer_steps()
        target = start + step_count

        milestones = {1, 2, 5, 10, 20}
        while env_state.get_timer_steps() < target:
            time.sleep(dt)
            remain = target - env_state.get_timer_steps()
            if remain in milestones:
                print(f"[async íƒ€ì´ë¨¸ ì§„í–‰] asynchronous_timerê°€ {remain} steps ë‚¨ì•˜ìŠµë‹ˆë‹¤.")
                milestones.remove(remain)

        # ë§Œë£Œ ì½œë°± íì— ì§ì ‘ ì‚½ì…
        llm_command_queue.put("asynchronous_timer_expired()")

    # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ëŒ€ê¸° í›„ ë§Œë£Œ ì²˜ë¦¬
    threading.Thread(
        target=_wait_and_expire,
        args=(steps, tool_call_id),
        daemon=True
    ).start()

    return Command(update={
        "messages": [
            ToolMessage(f"asynchronous_timer started: {timer}s ({steps} steps)", tool_call_id=tool_call_id)
        ]
    })

@tool
def asynchronous_timer_expired(
    tool_call_id: Annotated[str, InjectedToolCallId]
) -> Command:
    """
    ë¹„ë™ê¸° íƒ€ì´ë¨¸ê°€ ë§Œë£Œë˜ì—ˆì„ ë•Œ ìë™ìœ¼ë¡œ í˜¸ì¶œë˜ëŠ” ì´ë²¤íŠ¸ì…ë‹ˆë‹¤.

    ì´ ì´ë²¤íŠ¸ëŠ” ì˜ˆì•½ëœ ì§€ì—° ì‹œê°„ì´ ëë‚¬ìŒì„ ì‹œìŠ¤í…œì— ì•Œë¦¬ëŠ” ì—­í• ì„ í•˜ë©°,  
    ì´ë¥¼ í†µí•´ LLMì€ ì´í›„ ë™ì‘ì´ë‚˜ íŒë‹¨ì„ ìƒì„±í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤.

    ì‚¬ìš© ëª©ì :
    - `asynchronous_timer`ë¥¼ í†µí•´ ì„¤ì •ëœ ëŒ€ê¸° ì‹œê°„ì´ ëë‚¬ìŒì„ ì•Œë¦¼
    - ëŒ€ê¸° í›„ ì´ì–´ì§€ëŠ” í–‰ë™(ì˜ˆ: ë‹¤ìŒ ì´ë™, ì •ì±… ì „í™˜ ë“±)ì„ ì‹¤í–‰ ê°€ëŠ¥í•˜ê²Œ í•¨
    """
    llm_command_queue.put(
        "â° Timer expired! Considering past commands, suggest the next action."
    )
    return Command(update={
        "messages": [
            ToolMessage("asynchronous_timer_expired", tool_call_id=tool_call_id)
        ]
    })


@tool
def blocking_timer(
    timer: float,
    tool_call_id: Annotated[str, InjectedToolCallId]
) -> Command:
    """
    ğŸ”´ ìµœëŒ€ 0.5ì´ˆ ì´í•˜ì˜ ì§§ì€ ì§€ì—°ì„ ìœ„í•œ **ì •ë°€ ì°¨ë‹¨í˜• íƒ€ì´ë¨¸**ì…ë‹ˆë‹¤.

    ì´ íƒ€ì´ë¨¸ëŠ” ë§¤ìš° ì§§ì€ ì‹œê°„ ë™ì•ˆ LLMì˜ íë¦„ì„ ì¼ì‹œì ìœ¼ë¡œ ë©ˆì¶”ê³ ,  
    **ì •í™•í•œ íƒ€ì´ë° ì œì–´**(ì˜ˆ: ì ê¹ íšŒì „í•˜ê±°ë‚˜ ì ì‹œ ë©ˆì¶”ëŠ” ë™ì‘)ì— ì‚¬ìš©ë©ë‹ˆë‹¤.

    Args:
        timer (float): ì§€ì—° ì‹œê°„ (ë‹¨ìœ„: ì´ˆ).  
        â±ï¸ 0.01ì´ˆ ~ ìµœëŒ€ 0.5ì´ˆ ì‚¬ì´ì˜ ê°’ë§Œ í—ˆìš©ë©ë‹ˆë‹¤.  
        ì˜ˆ: `0.2`ëŠ” 200ë°€ë¦¬ì´ˆ ì§€ì—°ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.

    ì‚¬ìš© ì˜ˆì‹œ:
    - 0.3ì´ˆê°„ ì œìë¦¬ íšŒì „
    - ì†ë„ë¥¼ ì ì‹œ ìœ ì§€í•œ í›„ ë©ˆì¶”ê¸°
    - ì—°ì† ë™ì‘ ì‚¬ì´ì˜ íƒ€ì´ë° ë™ê¸°í™”

    âš ï¸ ì£¼ì˜:
    - **0.5ì´ˆë¥¼ ì´ˆê³¼í•˜ëŠ” ì§€ì—°ì—ëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.**
      ê¸´ ì´ë™(ì˜ˆ: 1ë¯¸í„° ê±·ê¸° ë“±)ì—ëŠ” `asynchronous_timer`ë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
    - `blocking_timer`ë¥¼ ê³¼ë„í•˜ê²Œ ì‚¬ìš©í•˜ë©´ LLM ì‘ë‹µ ì§€ì—°ì´ë‚˜ ì„±ëŠ¥ ì €í•˜ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

    ê¶Œì¥ ìš©ë„:
    - ë¹ ë¥´ê³  ê²°ì •ì ì¸ ì‹œê°„ ì œì–´ê°€ í•„ìš”í•œ ê²½ìš°ì—ë§Œ ì‚¬ìš©
    - LLM íë¦„ì´ ì¼ì‹œ ì •ì§€ë˜ì–´ë„ ê´œì°®ì€ ìƒí™©
    """
    env = env_state.get_env()
    dt = env.sim.get_physics_dt()
    steps = int(timer / dt)

    start = env_state.get_timer_steps()
    target = start + steps

    # Block until simulation timer reaches zero
    milestones = {1, 2, 5, 10, 20}
    while env_state.get_timer_steps() < target:
        time.sleep(dt)
        remain = target - env_state.get_timer_steps()
        if remain in milestones:
            print(f"[blocking íƒ€ì´ë¨¸ ì§„í–‰] blocking_timerê°€ {remain} steps ë‚¨ì•˜ìŠµë‹ˆë‹¤.")
            milestones.remove(remain)

    print("[blocking íƒ€ì´ë¨¸ ë§Œë£Œ] blocking_timerê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

    return Command(update={
        "messages": [
            ToolMessage(f"blocking_timer {timer}s ({steps} steps) complete", tool_call_id=tool_call_id)
        ]
    })

# 3) ê·¸ë˜í”„ ë¹Œë” ë° ToolNode ìƒì„±
# --- íˆ´ ëª©ë¡ì— ëª¨ë“  ë„êµ¬ ì¶”ê°€ ---
tools = [
    google_search_tool,
    human_assistance,
    time_travel,
    set_velocity,
    proprioception,
    switch_policy,
    process_rgb,
    process_depth,
    asynchronous_timer,
    asynchronous_timer_expired,
    blocking_timer,
]
tool_node = ToolNode(tools=tools)

# --- LLM ì´ˆê¸°í™” ---
llm = init_chat_model("openai:gpt-4.1")  # gpt 4.1 miniëŠ” íˆ´ ì„¤ëª…ì´ë‚˜ í”„ë¡¬í”„íŠ¸ë¥¼ ë¹¨ë¦¬ ìŠì–´ë²„ë¦¬ëŠ” ê²½í–¥ì´ ì‹¬í•˜ë‹¤.
llm_with_tools = llm.bind_tools(tools)

SYSTEM_PROMPT = """
ë„ˆëŠ” ë§µì´ ì£¼ì–´ì§€ì§€ ì•Šì€ ë‚¯ì„  í™˜ê²½ì—ì„œ ëª¨ë°”ì¼ ë¡œë´‡(ì‚¬ì¡±ë³´í–‰ ë¡œë´‡)ì„ ì œì–´í•˜ëŠ” AIì•¼. ëª©í‘œëŠ” ì£¼ì–´ì§„ ëª…ë ¹ì„ ìˆ˜í–‰í•˜ë©´ì„œ ì¥ì• ë¬¼ì— ë¶€ë”ªíˆì§€ ì•Šê³  ì•ˆì „í•˜ê²Œ ì´ë™í•˜ëŠ” ê²ƒì´ì•¼.
ì£¼ë³€í™˜ê²½ì„ íŒŒì•…í•  ë•Œ ê¹Šì´ ì´ë¯¸ì§€ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì‚¬ìš©í•˜ê³ , RGB ì´ë¯¸ì§€ëŠ” ë³´ì™„ì ìœ¼ë¡œ ì‚¬ìš©í•´. ë‘˜ ë‹¤ ë™ì‹œì— ì‚¬ìš©í•˜ëŠ” ê²ƒì€ ë”œë ˆì´ê°€ ë°œìƒí•˜ë¯€ë¡œ ì§€ì–‘í•´.

ë‹¤ìŒê³¼ ê°™ì€ ì›ì¹™ì„ ë°˜ë“œì‹œ ì§€ì¼œì•¼ í•´:

1. **ë¡œë´‡ì˜ ì›€ì§ì„ì€ í•­ìƒ ì ì§„ì ìœ¼ë¡œ ì¡°ì ˆ**í•´ì•¼ í•´. ì†ë„ë¥¼ ë¹ ë¥´ê²Œ ë°”ê¾¸ë©´ ë¡œë´‡ì´ ë¶ˆì•ˆì •í•´ì§€ë¯€ë¡œ, ì†ë„ëŠ” ì²œì²œíˆ ì˜¬ë¦¬ê³  ì²œì²œíˆ ì¤„ì´ë„ë¡ í•´.
    - ì„ ì†ë„ì˜ ê²½ìš°ëŠ” 0.5m/së¥¼ 0.2ì´ˆ ì •ë„ ìœ ì§€í•˜ê³  ì†ë„ë¥¼ 1m/së¡œ ì˜¬ë¦¬ê±°ë‚˜ ë°˜ëŒ€ì˜ ê²½ìš° 0.2ì´ˆ ì •ë„ ìœ ì§€í•˜ê³  0.0m/së¡œ ì¤„ì´ëŠ” ê²ƒì´ ì¢‹ìŒ
    - íšŒì „ ì†ë„ì˜ ê²½ìš°ëŠ” 0.5rad/së¥¼ 0.2ì´ˆ ì •ë„ ìœ ì§€í•˜ê³  1rad/së¡œ ì˜¬ë¦¬ê±°ë‚˜ ë°˜ëŒ€ì˜ ê²½ìš° 0.2ì´ˆ ì •ë„ ìœ ì§€í•˜ê³  0.0rad/së¡œ ì¤„ì´ëŠ” ê²ƒì´ ì¢‹ìŒ

2. **ë¡œë´‡ì˜ ìì„¸(Proprioception)**ë¥¼ ì¸ì‹í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•´. ìì„¸ì™€ ì ‘ì´‰ ì •ë³´, ê´€ì ˆ ìƒíƒœ ë“±ì„ í™œìš©í•´ì„œ ë¡œë´‡ì´ ê· í˜•ì„ ìœ ì§€í•˜ê³  ìˆëŠ”ì§€, ì•ˆì •ì ì¸ì§€ íŒë‹¨í•´ì•¼ í•´.

3. **ì¥ì• ë¬¼ì— ê°€ê¹Œì›Œì§€ë©´ ì†ë„ë¥¼ ì¤„ì—¬ì•¼ í•´.** ì¶©ëŒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ í™˜ê²½ ë¶„ì„ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìœ„í—˜í•œ ìƒí™©ì—ì„œëŠ” ë©ˆì¶”ê±°ë‚˜ ì²œì²œíˆ ì´ë™í•˜ë„ë¡ í•´.

4. **ì¹´ë©”ë¼ ì‹œì•¼ë¡œ ì£¼ë³€ì´ ì˜ ë³´ì´ì§€ ì•Šìœ¼ë©´**, ì£¼ë³€ì„ ì‚´í´ì•¼ í•´. ì¢Œìš° ë˜ëŠ” ë’¤ë¡œ ì²œì²œíˆ íšŒì „í•˜ë©´ì„œ ë§‰ë‹¤ë¥¸ ê¸¸ì´ë‚˜ ë§‰íŒ í†µë¡œì—ì„œ ë²—ì–´ë‚  ìˆ˜ ìˆëŠ” ë°©í–¥ì„ íƒìƒ‰í•´.

5. **ì •í™•í•œ íšŒì „ì´ ì–´ë ¤ìš°ë¯€ë¡œ**, íšŒì „ì€ ì¼ì •í•œ ì†ë„ì™€ ì‹œê°„ìœ¼ë¡œ ìˆ˜í–‰í•˜ê³ , ê·¸ ê²°ê³¼ë¥¼ ê¸°ì–µí•´ì„œ ìŠ¤ìŠ¤ë¡œ ì–¼ë§ˆë‚˜ íšŒì „í–ˆëŠ”ì§€ ì¶”ì •í•˜ê³  ì¡°ì •í•´ì•¼ í•´. ì˜ˆë¥¼ ë“¤ì–´:
   - `wz = 1.0` ì†ë„ë¡œ 0.3ì´ˆ íšŒì „
   - `wz = 0.5` ì†ë„ë¡œ 0.5ì´ˆ íšŒì „
   ì´ì²˜ëŸ¼ íšŒì „ì˜ ê²°ê³¼ë¥¼ ì¶”ì •í•˜ê³  ëˆ„ì í•´ì„œ ê¸°ì–µí•´. ê·¸ë˜ì•¼ ë” ë‚˜ì€ íšŒì „ ì œì–´ê°€ ê°€ëŠ¥í•´ì§ˆ ê±°ì•¼.

6. ë¡œë´‡ì˜ í¬ê¸°ëŠ” **ìµœëŒ€ ë†’ì´ 0.4m**, **ë„ˆë¹„ 0.31m**ì•¼. ì´ í¬ê¸°ë¥¼ ê³ ë ¤í•´ì„œ ì¢ì€ í†µë¡œ ì§„ì…ì´ë‚˜ ì¥ì• ë¬¼ ì‚¬ì´ í†µê³¼ ì—¬ë¶€ë¥¼ íŒë‹¨í•´.

7. **í•œ ë²ˆì— ì´ë™í•˜ëŠ” ê±°ë¦¬ëŠ” ì•ì— ë³µë„ê°€ ì•„ë‹Œ ê²½ìš° ë°˜ë“œì‹œ ì§§ê²Œ ê³„íší•´ì•¼ í•´.** 
   - ì§€í˜•ì— ëŒ€í•œ ì‚¬ì „ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°, ë¡œë´‡ì€ í•œ ë²ˆì— **0.2~0.3ì´ˆ**, ë˜ëŠ” **0.2~0.3m ì´í•˜**ë¡œë§Œ ì´ë™í•´ì•¼ í•´.
   - ì´ë ‡ê²Œ ì‘ì€ ë‹¨ìœ„ë¡œ ì¡°ê¸ˆì”© ì´ë™í•˜ë©´ì„œ **ìì£¼ íŒë‹¨**í•˜ê³  ìƒí™©ì„ ë‹¤ì‹œ ë¶„ì„í•˜ëŠ” ê²ƒì´ í›¨ì”¬ ì•ˆì „í•˜ê³  ìœ ë¦¬í•´.
   - ì—°ì†ëœ íŒë‹¨ì„ í†µí•´ ë¯¸ì§€ì˜ í™˜ê²½ì„ íƒìƒ‰í•˜ê³ , ì ì ˆí•œ íƒ€ì´ë°ì— íšŒì „í•˜ê±°ë‚˜ ì •ì§€í•  ìˆ˜ ìˆë„ë¡ ê³„íší•˜ë¼.
   - ì•ì— ê¸¸ê²Œ ì´ì–´ì§„ ë³µë„ê°€ ìˆëŠ” ê²½ìš°, ë¡œë´‡ì€ í•œ ë²ˆì— **0.5ì´ˆ ì´ìƒ**, ë˜ëŠ” **0.5m ì´ìƒ** ì´ë™í•  ìˆ˜ ìˆë‹¤.

8. **ê¹Šì´ ì´ë¯¸ì§€ë¡œë¶€í„° ì¥ì• ë¬¼ì— ëŒ€í•œ ëŒ€ëµì ì¸ ê±°ë¦¬ë¥¼ ì–»ì€ ê²½ìš°, ì¡°ê¸ˆ ë” ë¨¼ ê±°ë¦¬ë¥¼ ê³„íší•  ìˆ˜ ìˆë‹¤.**
    - ì •ë©´ì˜ ì¥ì• ë¬¼ì´ 5m ì •ë„ë¼ê³  ì¶”ì •ì´ ëœë‹¤ë©´, 3~4m ì •ë„ ê°„ ë‹¤ìŒ ë‹¤ì‹œ íŒë‹¨í•˜ì—¬ ì •ë©´ì˜ ì¥ì• ë¬¼ê³¼ ì–¼ë§ˆë‚˜ ê°€ê¹Œì›Œì¡ŒëŠ”ì§€ íŒë‹¨í•˜ë©´ ì´ì „ì˜ ì¶”ì •ì¹˜ê°€ ëª…í™•í•¨ì„ ì•Œ ìˆ˜ ìˆë‹¤.
    - ì¥ì• ë¬¼ê¹Œì§€ì˜ ê±°ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •ë©´ì— ë³µë„ê°€ ìˆë‹¤ê³  ìƒê°ëœë‹¤ë©´, ì•½ê°„ ëª¸ì„ íšŒì „í•˜ë©´ì„œ ì´ë™í•˜ì—¬ ëª¨ì„œë¦¬ì— ë„ë‹¬í–ˆì„ ë•Œ ë³µë„ë¥¼ ë³¼ ìˆ˜ ìˆë„ë¡ ìì„¸ë¥¼ ì¡°ì •í•˜ë¼.

ë„ˆëŠ” ì´ëŸ¬í•œ ì›ì¹™ì„ ì§€í‚¤ë©´ì„œ, ì œê³µëœ ë„êµ¬(tool)ë¥¼ ì ì ˆíˆ í™œìš©í•´ ëª©í‘œë¥¼ ë‹¬ì„±í•´ì•¼ í•´.
"""



def chatbot(state: State):
    """ì±—ë´‡ ë…¸ë“œ: ì´ì „ ë©”ì‹œì§€ë¥¼ ë°›ì•„ LLM ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤."""
    msgs = [SYSTEM_PROMPT] + state["messages"]
    response = llm_with_tools.invoke(msgs)
    return {"messages": [response]}

# --- ê·¸ë˜í”„ ë¹Œë” ì„¤ì • ---
graph_builder = StateGraph(State)
graph_builder.add_node("chatbot", chatbot)
graph_builder.add_node("tools", tool_node)


def route_tools(state: State):
    """
    ë§ˆì§€ë§‰ ë©”ì‹œì§€ì— tool_callsê°€ ìˆìœ¼ë©´ 'tools' ë…¸ë“œë¡œ,
    ì•„ë‹ˆë©´ ENDë¡œ ë¼ìš°íŒ…í•©ë‹ˆë‹¤.
    """
    if isinstance(state, list):
        ai_message = state[-1]
    elif messages := state.get("messages", []):
        ai_message = messages[-1]
    else:
        raise ValueError(f"tool_edge ì…ë ¥ stateì— ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤: {state}")
    if hasattr(ai_message, "tool_calls") and len(ai_message.tool_calls) > 0:
        return "tools"
    return END


graph_builder.add_edge(START, "chatbot")
graph_builder.add_conditional_edges(
    "chatbot",
    route_tools,
    {"tools": "tools", END: END},
)

graph_builder.add_edge("tools", "chatbot")


# --- ë©”ëª¨ë¦¬ ë° ê·¸ë˜í”„ ì»´íŒŒì¼ ---
memory = MemorySaver()
graph = graph_builder.compile(checkpointer=memory)
config = {
    "configurable": {"thread_id": "1"},
    "recursion_limit": 250
}

# === [ëŒ€í™” ìŠ¤íŠ¸ë¦¼ í•¨ìˆ˜ ë° ë©”ì¸ ë£¨í”„] ===
llm_response_queue = queue.Queue()
last_velocity = None
def stream_graph_updates(env, user_input: str):
    """ìœ ì € ì…ë ¥ì„ ë°›ì•„ LangGraphë¡œ ëŒ€í™” ìŠ¤íŠ¸ë¦¼ì„ ì¶œë ¥í•©ë‹ˆë‹¤."""
    global last_velocity
    if isinstance(user_input, Command):
        events = graph.stream(user_input, config, stream_mode="values")
    else:
        events = graph.stream(
            {"messages": [{"role": "user", "content": user_input}]},
            config,
            stream_mode="values",
        )

    for event in events:
        # human-in-the-loop ì¸í„°ëŸ½íŠ¸ ë°œìƒ ì‹œ
        if "__interrupt__" in event:
            # interrupt()ì—ì„œ ë„˜ì–´ì˜¨ ì§ˆë¬¸(prompt)ë¥¼ êº¼ë‚´ì„œ
            prompt = event["__interrupt__"][0].value
            answer = input(f"{prompt}")
            return stream_graph_updates(Command(resume={"data": answer}))
        if "messages" not in event:
            continue

        # ToolMessage ì¤‘ set_velocityë§Œ íŒŒì‹±
        for msg in event["messages"]:
            if hasattr(msg, "name") and msg.name == "set_velocity":
                try:
                    data = json.loads(msg.content)
                    vx, vy, wz = data["velocity"]["vx"], data["velocity"]["vy"], data["velocity"]["wz"]
                    # print(f"[LLM output] vx={vx}, vy={vy}, wz={wz}")  # LLM ëª…ë ¹ ì¶œë ¥
                    vel = torch.tensor([[vx, vy, wz]], device=env.device)
                    last_velocity = vel.repeat(env.num_envs, 1)
                except json.JSONDecodeError as e:
                    print(f"[WARNING] set_velocity íŒŒì‹± ì‹¤íŒ¨: {e}")
        
        # ì¼ë°˜ì ì¸ ëŒ€í™” ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬
        event["messages"][-1].pretty_print()

def llm_worker(prompt: str, env):
    """
    ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ LLM(stream_graph_updates)ì„ í˜¸ì¶œí•˜ê³ ,
    ëë‚˜ë©´ ì‘ë‹µ íì— Trueë¥¼ ë„£ì–´ì¤ë‹ˆë‹¤.
    """
    stream_graph_updates(env, prompt)
    llm_response_queue.put(True)

# â€” 4. ì…ë ¥ í & ìŠ¤ë ˆë“œ â€”
llm_command_queue = queue.Queue()

def start_input_listener():
    def _listen():
        while True:
            cmd = input().strip()  # "[ì‹œìŠ¤í…œ]ë¡œë´‡ ëª…ë ¹ ì…ë ¥: "
            if cmd:
                llm_command_queue.put(cmd)
    threading.Thread(target=_listen, daemon=True).start()


# â€” 5. ì‹œë®¬ë ˆì´ì…˜ ì½œë°± í•¨ìˆ˜ â€”
def llm_command_callback(env):
    """
    env.num_envs, env.deviceë¥¼ ê°€ì§„ ì‹œë®¬ë ˆì´ì…˜ í™˜ê²½ì—ì„œ
    ë§¤ ìŠ¤í… í˜¸ì¶œí•˜ì—¬ torch.Tensor ì†ë„ ëª…ë ¹ì„ ëŒë ¤ì¤ë‹ˆë‹¤.
    """
    global last_velocity
    env_state.set_env(env)

    # 1) ì‹œë®¬ë ˆì´ì…˜ ìŠ¤í… ì¹´ìš´íŠ¸
    steps = env_state.get_timer_steps()
    env_state.set_timer(steps + 1)

    # 2) ì…ë ¥ íì—ì„œ ìƒˆ í”„ë¡¬í”„íŠ¸ êº¼ë‚´ê¸°
    try:
        prompt = llm_command_queue.get_nowait()
    except queue.Empty:
        prompt = None

    # 3) ìƒˆ í”„ë¡¬í”„íŠ¸ê°€ ìˆìœ¼ë©´, ì›Œì»¤ ìŠ¤ë ˆë“œë¡œ LLM í˜¸ì¶œ ë¶„ë¦¬
    if prompt:
        if prompt.lower() in ["quit", "exit", "q", "ì¢…ë£Œ"]:
            print("Goodbye!")
            exit()

        threading.Thread(
            target=llm_worker,
            args=(prompt, env),
            daemon=True
        ).start()

    # 4) ì‘ë‹µ í í™•ì¸: ì›Œì»¤ê°€ ëë‚¬ìœ¼ë©´ last_velocityëŠ” ì´ë¯¸ ê°±ì‹ ëœ ìƒíƒœ
    try:
        done = llm_response_queue.get_nowait()
        if done:
            # (í•„ìš”ì‹œ) ì™„ë£Œ ë¡œê·¸ë‚˜ ì¶”ê°€ ì²˜ë¦¬
            # print("\n[ì‹œìŠ¤í…œ] LLM ëª…ë ¹ ì‹¤í–‰ ì™„ë£Œ\n")
            pass
    except queue.Empty:
        pass

    if last_velocity is None:
        return torch.zeros((env.num_envs, 3), device=env.device)

    return last_velocity
